% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ppc-loo.R
\name{PPC-loo}
\alias{PPC-loo}
\alias{ppc_loo_pit}
\title{LOO predictive checks}
\usage{
ppc_loo_pit(y, yrep, lw, compare = c("uniform", "normal"), ..., size = 2,
  alpha = 0.5)
}
\arguments{
\item{y}{A vector of observations. See \strong{Details}.}

\item{yrep}{An \eqn{S} by \eqn{N} matrix of draws from the posterior
predictive distribution, where \eqn{S} is the size of the posterior sample
(or subset of the posterior sample used to generate \code{yrep}) and
\eqn{N} is the number of observations (the length of \code{y}). The columns
of \code{yrep} should be in the same order as the data points in \code{y}
for the plots to make sense. See \strong{Details} for additional
instructions.}

\item{lw}{A matrix of (smoothed) log weights with the same dimensions as
\code{yrep}.}

\item{compare}{For \code{ppc_loo_pit}, a string that can be either
\copde{"uniform"} or \code{"normal"}. If \code{"uniform"} (the default) the
Q-Q plot compares computed PIT values to the standard uniform distribution.
If \code{compare="normal"}, the Q-Q plot compares standardized PIT values
to the standard normal distribution.}

\item{...}{Currently unused.}

\item{size, alpha}{Passed to \code{\link[ggplot2]{geom_point}} to control the
appearance of the points.}
}
\description{
LOO predictive checks
}
\section{Plot Descriptions}{

\describe{
\item{\code{ppc_loo_pit}}{
 The calibration of marginal predictions can be checked with probability
 integral transformation (PIT) checks. LOO improves the check by avoiding the
 double use of data. See the section on marginal predictive checks in Gelman
 et al. (2013, p. 152--153). The default LOO probability integral
 transformation (PIT) predictive check is a quantile-quantile (Q-Q) plot
 comparing the LOO PITs to the standard uniform distribution. Alternatively,
 setting the \code{compare} argument to \code{"normal"} will produce a Q-Q
 plot comparing standardized PIT values may to the standard normal
 distribution.
}
}
}

\examples{
color_scheme_set("red")

\dontrun{
library(rstanarm)
library(loo)

head(radon)
fit <- stan_lmer(log_radon ~ floor + log_uranium + floor:log_uranium
                   + (1 + floor | county), data = radon)
y <- radon$log_radon
yrep <- posterior_predict(fit)
psis <- psislw(-log_lik(fit))
ppc_loo_pit(y, yrep, lw = psis$lw_smooth)
ppc_loo_pit(y, yrep, lw = psis$lw_smooth, compare = "normal")
}

}
\references{
Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari,
  A., and Rubin, D. B. (2013). \emph{Bayesian Data Analysis.} Chapman & Hall/CRC
  Press, London, third edition. (p. 152--153)

Vehtari, A., Gelman, A., and Gabry, J. (2016a). Practical
  Bayesian model evaluation using leave-one-out cross-validation and WAIC.
  \emph{Statistics and Computing}. Advance online publication.
  doi:10.1007/s11222-016-9696-4. arXiv preprint:
  \url{http://arxiv.org/abs/1507.04544/}
}
\seealso{
Other PPCs: \code{\link{PPC-discrete}},
  \code{\link{PPC-distributions}},
  \code{\link{PPC-errors}}, \code{\link{PPC-intervals}},
  \code{\link{PPC-overview}},
  \code{\link{PPC-scatterplots}},
  \code{\link{PPC-test-statistics}}
}
