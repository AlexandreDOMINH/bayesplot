<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Graphical posterior predictive checks using the bayesplot package • bayesplot</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">bayesplot</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../articles/index.html">Vignettes</a>
</li>
<li>
  <a href="../reference/index.html">Functions</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Other Packages
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="http://mc-stan.org/rstan">rstan</a>
    </li>
    <li>
      <a href="http://mc-stan.org/rstanarm">rstanarm</a>
    </li>
    <li>
      <a href="http://mc-stan.org/shinystan">shinystan</a>
    </li>
    <li>
      <a href="http://mc-stan.org/loo">loo</a>
    </li>
    <li>
      <a href="http://mc-stan.org/rstantools">rstantools</a>
    </li>
  </ul>
</li>
<li>
  <a href="http://mc-stan.org">Stan</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://twitter.com/mcmc_stan">
    <span class="fa fa-twitter"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/stan-dev/bayesplot">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Graphical posterior predictive checks using the bayesplot package</h1>
                        <h4 class="author">Jonah Gabry</h4>
            
            <h4 class="date">2017-08-03</h4>
          </div>

    
    
<div class="contents">
<p>This vignette focuses on graphical posterior predictive checks (PPC). Plots of parameter estimates from MCMC draws are covered in the separate vignette <a href="MCMC.html">Plotting MCMC draws using the bayesplot package</a>, and MCMC diagnostics are covered in <a href="MCMC-diagnostics.html">Visual MCMC diagnostics using the bayesplot package</a>.</p>
<div id="overview" class="section level2">
<h2 class="hasAnchor">
<a href="#overview" class="anchor"></a>Overview</h2>
<p>The <strong>bayesplot</strong> package provides various plotting functions for <em>graphical posterior predictive checking</em>, that is, creating graphical displays comparing observed data to simulated data from the posterior predictive distribution.</p>
<p>The idea behind posterior predictive checking is simple: if a model is a good fit then we should be able to use it to generate data that looks a lot like the data we observed.</p>
<div id="posterior-predictive-distribution" class="section level4">
<h4 class="hasAnchor">
<a href="#posterior-predictive-distribution" class="anchor"></a>Posterior predictive distribution</h4>
<p>To generate the data used for posterior predictive checks (PPCs) we simulate from the <em>posterior predictive distribution</em> The posterior predictive distribution is the distribution of the outcome variable implied by a model after using the observed data <span class="math inline">\(y\)</span> (a vector of <span class="math inline">\(N\)</span> outcome values) to update our beliefs about unknown model parameters <span class="math inline">\(\theta\)</span>. The posterior predictive distribution for observation <span class="math inline">\(\widetilde{y}\)</span> can be written as <span class="math display">\[p(\widetilde{y} \,|\, y) = \int
p(\widetilde{y} \,|\, \theta) \, p(\theta \,|\, y) \, d\theta.\]</span> Typically we will also condition on <span class="math inline">\(X\)</span> (a matrix of predictor variables).</p>
<p>For each draw (simulation) <span class="math inline">\(s = 1, \ldots, S\)</span> of the parameters from the posterior distribution, <span class="math inline">\(\theta^{(s)} \sim p(\theta \,|\, y)\)</span>, we draw an entire vector of <span class="math inline">\(N\)</span> outcomes <span class="math inline">\(\widetilde{y}^{(s)}\)</span> from the posterior predictive distribution by simulating from the data model conditional on parameters <span class="math inline">\(\theta^{(s)}\)</span>. The result is an <span class="math inline">\(S \times N\)</span> matrix of draws <span class="math inline">\(\widetilde{y}\)</span>.</p>
<p>When simulating from the posterior predictive distribution we can use either the same values of the predictors <span class="math inline">\(X\)</span> that we used when fitting the model or new observations of those predictors. When we use the same values of <span class="math inline">\(X\)</span> we denote the resulting simulations by <span class="math inline">\(y^{rep}\)</span>, as they can be thought of as replications of the outcome <span class="math inline">\(y\)</span> rather than predictions for future observations (<span class="math inline">\(\widetilde{y}\)</span> using predictors <span class="math inline">\(\widetilde{X}\)</span>). This corresponds to the notation from Gelman et. al. (2013) and is the notation used throughout the package documentation.</p>
</div>
</div>
<div id="graphical-posterior-predictive-checks" class="section level2">
<h2 class="hasAnchor">
<a href="#graphical-posterior-predictive-checks" class="anchor"></a>Graphical posterior predictive checks</h2>
<p>Using the replicated datasets drawn from the posterior predictive distribution, the functions in the <strong>bayesplot</strong> package create various graphical displays comparing the observed data <span class="math inline">\(y\)</span> to the replications. The names of the <strong>bayesplot</strong> plotting functions for posterior predictive checking all have the prefix <code>ppc_</code>.</p>
<p>To demonstrate some of the various PPCs that can be created with the <strong>bayesplot</strong> package we’ll use an example of comparing Poisson and Negative binomial regression models from the <a href="https://CRAN.R-project.org/package=rstanarm"><strong>rstanarm</strong></a> package vignette <a href="https://CRAN.R-project.org/package=rstanarm/vignettes/count.html"><em>stan_glm: GLMs for Count Data</em></a> (Gabry and Goodrich, 2016).</p>
<blockquote>
<p>We want to make inferences about the efficacy of a certain pest management system at reducing the number of roaches in urban apartments. […] The regression predictors for the model are the pre-treatment number of roaches <code>roach1</code>, the treatment indicator <code>treatment</code>, and a variable <code>senior</code> indicating whether the apartment is in a building restricted to elderly residents. Because the number of days for which the roach traps were used is not the same for all apartments in the sample, we include it as an exposure […].</p>
</blockquote>
<p>First we fit a Poisson regression model with outcome variable <code>y</code> representing the roach count in each apartment at the end of the experiment.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">"rstanarm"</span>)
<span class="kw">head</span>(roaches) <span class="co"># see help("rstanarm-datasets")</span>

roaches$roach1 &lt;-<span class="st"> </span>roaches$roach1 /<span class="st"> </span><span class="dv">100</span> <span class="co"># pre-treatment number of roaches (in 100s)</span>
fit_poisson &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(y ~<span class="st"> </span>roach1 +<span class="st"> </span>treatment +<span class="st"> </span>senior,
                        <span class="dt">offset =</span> <span class="kw">log</span>(exposure2),
                        <span class="dt">family =</span> <span class="kw">poisson</span>(<span class="dt">link =</span> <span class="st">"log"</span>),
                        <span class="dt">data =</span> roaches,
                        <span class="dt">seed =</span> <span class="dv">1111</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(fit_poisson)</code></pre></div>
<pre><code>stan_glm
 family:   poisson [log]
 formula:  y ~ roach1 + treatment + senior
 num. obs: 262
------

Estimates:
            Median MAD_SD
(Intercept)  3.1    0.0  
roach1       0.7    0.0  
treatment   -0.5    0.0  
senior      -0.4    0.0  

Sample avg. posterior predictive 
distribution of y (X = xbar):
         Median MAD_SD
mean_PPD 25.7    0.4  

------
For info on the priors used see help('prior_summary.stanreg').</code></pre>
<p>We’ll also fit the negative binomial model that we’ll compare to the poisson:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit_nb &lt;-<span class="st"> </span><span class="kw">update</span>(fit_poisson, <span class="dt">family =</span> <span class="st">"neg_binomial_2"</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(fit_nb)</code></pre></div>
<pre><code>stan_glm
 family:   neg_binomial_2 [log]
 formula:  y ~ roach1 + treatment + senior
 num. obs: 262
------

Estimates:
                      Median MAD_SD
(Intercept)            2.8    0.2  
roach1                 1.3    0.2  
treatment             -0.8    0.2  
senior                -0.3    0.3  
reciprocal_dispersion  0.3    0.0  

Sample avg. posterior predictive 
distribution of y (X = xbar):
         Median MAD_SD
mean_PPD 49.7   30.0  

------
For info on the priors used see help('prior_summary.stanreg').</code></pre>
<p>In order to use the PPC functions from the <strong>bayesplot</strong> package we need a matrix of draws from the posterior predictive distribution. Since we fit the models using <strong>rstanarm</strong> we can use its <code>posterior_predict</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">yrep_poisson &lt;-<span class="st"> </span><span class="kw">posterior_predict</span>(fit_poisson, <span class="dt">draws =</span> <span class="dv">500</span>)
yrep_nb &lt;-<span class="st"> </span><span class="kw">posterior_predict</span>(fit_nb, <span class="dt">draws =</span> <span class="dv">500</span>)
<span class="kw">dim</span>(yrep_poisson)</code></pre></div>
<pre><code>[1] 500 262</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dim</span>(yrep_nb)</code></pre></div>
<pre><code>[1] 500 262</code></pre>
<p>For each of the <code>yrep</code> matrices, every row is a draw from the posterior predictive distribution, i.e. a vector with one element for each of the data points in <code>y</code>.</p>
<div id="histograms-and-density-estimates" class="section level3">
<h3 class="hasAnchor">
<a href="#histograms-and-density-estimates" class="anchor"></a>Histograms and density estimates</h3>
<p>The first PPC we’ll look at is a comparison of the distribution of <code>y</code> and the distributions of some of the simulated datasets (rows) in the <code>yrep</code> matrix.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">"ggplot2"</span>)
<span class="kw">library</span>(<span class="st">"bayesplot"</span>)

<span class="kw"><a href="../reference/bayesplot-colors.html">color_scheme_set</a></span>(<span class="st">"brightblue"</span>) <span class="co"># see help("bayesplot-colors")</span>

y &lt;-<span class="st"> </span>roaches$y
<span class="kw"><a href="../reference/PPC-distributions.html">ppc_dens_overlay</a></span>(y, yrep_poisson[<span class="dv">1</span>:<span class="dv">50</span>, ])</code></pre></div>
<p><img src="PPC_files/figure-html/ppc_dens_overlay-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>In the plot above, the dark line is the distribution of the observed outcomes <code>y</code> and each of the 50 lighter lines is the kernel density estimate of one of the replications of <code>y</code> from the posterior predictive distribution (i.e., one of the rows in <code>yrep</code>). This plot makes it easy to see that this model fails to account for large proportion of zeros in <code>y</code>. That is, the model predicts fewer zeros than were actually observed.</p>
<p>We could see the same thing by looking at separate histograms of <code>y</code> and some of the <code>yrep</code> datasets using the <code>ppc_hist</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/PPC-distributions.html">ppc_hist</a></span>(y, yrep_poisson[<span class="dv">1</span>:<span class="dv">5</span>, ])</code></pre></div>
<p><img src="PPC_files/figure-html/ppc_hist-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>The same plot for the negative binomial model looks much different:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/PPC-distributions.html">ppc_hist</a></span>(y, yrep_nb[<span class="dv">1</span>:<span class="dv">5</span>, ])</code></pre></div>
<p><img src="PPC_files/figure-html/ppc_hist-nb-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>The negative binomial model does better handling the number of zeros in the data, but it occasionally predicts values that are way too large, which is why the x-axes extend to such high values in the plot and make it difficult to read. To see the predictions for the smaller values more clearly we can zoom in:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/PPC-distributions.html">ppc_hist</a></span>(y, yrep_nb[<span class="dv">1</span>:<span class="dv">5</span>, ], <span class="dt">binwidth =</span> <span class="dv">20</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(-<span class="dv">1</span>, <span class="dv">500</span>))</code></pre></div>
<p><img src="PPC_files/figure-html/ppc_hist-nb-2-1.png" width="60%" style="display: block; margin: auto;"></p>
</div>
<div id="distributions-of-test-statistics" class="section level3">
<h3 class="hasAnchor">
<a href="#distributions-of-test-statistics" class="anchor"></a>Distributions of test statistics</h3>
<p>Another way to see that the Poisson model predicts too few zeros is to use the <code>ppc_stat</code> function to look at the distribution of the proportion of zeros over the replicated datasets from the posterior predictive distribution in <code>yrep</code> and compare to the proportion of observed zeros in <code>y</code>.</p>
<p>First we define a function that takes a vector as input and returns the proportion of zeros:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">prop_zero &lt;-<span class="st"> </span>function(x) <span class="kw">mean</span>(x ==<span class="st"> </span><span class="dv">0</span>)
<span class="kw">prop_zero</span>(y) <span class="co"># check proportion of zeros in y</span></code></pre></div>
<pre><code>[1] 0.3587786</code></pre>
<p>Then we can use this function as the <code>stat</code> argument to <code>ppc_stat</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/PPC-test-statistics.html">ppc_stat</a></span>(y, yrep_poisson, <span class="dt">stat =</span> <span class="st">"prop_zero"</span>)</code></pre></div>
<p><img src="PPC_files/figure-html/ppc_stat-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>In the plot the dark line is at the value <span class="math inline">\(T(y)\)</span>, i.e. the value of the test statistic computed from the observed <span class="math inline">\(y\)</span>, in this case <code>prop_zero(y)</code>. It’s hard to see because almost all the datasets in <code>yrep</code> have no zeros, but the lighter bar is actually a histogram of the the proportion of zeros in each of the replicated datasets.</p>
<p>Here’s the same plot for the negative binomial model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/PPC-test-statistics.html">ppc_stat</a></span>(y, yrep_nb, <span class="dt">stat =</span> <span class="st">"prop_zero"</span>)</code></pre></div>
<p><img src="PPC_files/figure-html/ppc_stat-nb-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>Again we see that the negative binomial model does a much better job predicting the proportion of observed zeros than the Poisson.</p>
<p>However, if we look instead at the distribution of the maximum value in the replications then we can see that the Poisson model makes more realistic predictions than the negative binomial:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/PPC-test-statistics.html">ppc_stat</a></span>(y, yrep_poisson, <span class="dt">stat =</span> <span class="st">"max"</span>)</code></pre></div>
<p><img src="PPC_files/figure-html/ppc_stat-max-1.png" width="60%" style="display: block; margin: auto;"></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/PPC-test-statistics.html">ppc_stat</a></span>(y, yrep_nb, <span class="dt">stat =</span> <span class="st">"max"</span>)</code></pre></div>
<p><img src="PPC_files/figure-html/ppc_stat-max-2.png" width="60%" style="display: block; margin: auto;"></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/PPC-test-statistics.html">ppc_stat</a></span>(y, yrep_nb, <span class="dt">stat =</span> <span class="st">"max"</span>, <span class="dt">binwidth =</span> <span class="dv">100</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(-<span class="dv">1</span>, <span class="dv">5000</span>))</code></pre></div>
<p><img src="PPC_files/figure-html/ppc_stat-max-3.png" width="60%" style="display: block; margin: auto;"></p>
</div>
<div id="other-ppcs-and-ppcs-by-group" class="section level3">
<h3 class="hasAnchor">
<a href="#other-ppcs-and-ppcs-by-group" class="anchor"></a>Other PPCs and PPCs by group</h3>
<p>There are many additional PPCs available, including plots of predictive intervals, distributions of predictive errors, and more. For links to the documentation for all of the various PPC plots see <code>help("PPC-overview")</code>. The <code>available_ppc</code> function can also be used to list the names of all PPC plotting functions:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/available_ppc.html">available_ppc</a></span>()</code></pre></div>
<pre><code>bayesplot PPC module:
  ppc_bars
  ppc_bars_grouped
  ppc_boxplot
  ppc_dens
  ppc_dens_overlay
  ppc_ecdf_overlay
  ppc_error_binned
  ppc_error_hist
  ppc_error_hist_grouped
  ppc_error_scatter
  ppc_error_scatter_avg
  ppc_error_scatter_avg_vs_x
  ppc_freqpoly
  ppc_freqpoly_grouped
  ppc_hist
  ppc_intervals
  ppc_intervals_grouped
  ppc_loo_intervals
  ppc_loo_pit
  ppc_loo_ribbon
  ppc_ribbon
  ppc_ribbon_grouped
  ppc_rootogram
  ppc_scatter
  ppc_scatter_avg
  ppc_scatter_avg_grouped
  ppc_stat
  ppc_stat_2d
  ppc_stat_freqpoly_grouped
  ppc_stat_grouped
  ppc_violin_grouped</code></pre>
<p>Many of the available PPCs can also be carried out within levels of a grouping variable. Any function for PPCs by group will have a name ending in <code>_grouped</code> and will accept an additional argument <code>group</code>. For example, <code>ppc_stat_grouped</code> is the same as <code>ppc_stat</code> except that the test statistics are computed within levels of the grouping variable and a separate plot is made for each level:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/PPC-test-statistics.html">ppc_stat_grouped</a></span>(y, yrep_nb, <span class="dt">group =</span> roaches$treatment, <span class="dt">stat =</span> <span class="st">"prop_zero"</span>)</code></pre></div>
<p><img src="PPC_files/figure-html/ppc_stat_grouped-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>The full list of currently available <code>_grouped</code> functions is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/available_ppc.html">available_ppc</a></span>(<span class="dt">pattern =</span> <span class="st">"_grouped"</span>)</code></pre></div>
<pre><code>bayesplot PPC module:
(matching pattern '_grouped') 
  ppc_bars_grouped
  ppc_error_hist_grouped
  ppc_freqpoly_grouped
  ppc_intervals_grouped
  ppc_ribbon_grouped
  ppc_scatter_avg_grouped
  ppc_stat_freqpoly_grouped
  ppc_stat_grouped
  ppc_violin_grouped</code></pre>
</div>
</div>
<div id="providing-an-interface-to-bayesplot-ppcs-from-another-package" class="section level2">
<h2 class="hasAnchor">
<a href="#providing-an-interface-to-bayesplot-ppcs-from-another-package" class="anchor"></a>Providing an interface to bayesplot PPCs from another package</h2>
<p>The <strong>bayesplot</strong> package provides the S3 generic function <code>pp_check</code>. Authors of R packages for Bayesian inference are encouraged to define methods for the fitted model objects created by their packages. This will hopefully be convenient for both users and developers and contribute to the use of the same naming conventions across many of the R packages for Bayesian data analysis.</p>
<p>To provide an interface to <strong>bayesplot</strong> from your package, you can very easily define a <code>pp_check</code> method (or multiple <code>pp_check</code> methods) for the fitted model objects created by your package. All a <code>pp_check</code> method needs to do is provide the <code>y</code> vector and <code>yrep</code> matrix arguments to the various plotting functions included in <strong>bayesplot</strong>.</p>
<div id="defining-a-pp_check-method" class="section level3">
<h3 class="hasAnchor">
<a href="#defining-a-pp_check-method" class="anchor"></a>Defining a <code>pp_check</code> method</h3>
<p>Here is an example for how to define a simple <code>pp_check</code> method in a package that creates fitted model objects of class <code>"foo"</code>. We will define a method <code>pp_check.foo</code> that extracts the data <code>y</code> and the draws from the posterior predictive distribution <code>yrep</code> from an object of class <code>"foo"</code> and then calls one of the plotting functions from <strong>bayesplot</strong>.</p>
<p>Suppose that objects of class <code>"foo"</code> are lists with named components, two of which are <code>y</code> and <code>yrep</code>. Here’s a simple method <code>pp_check.foo</code> that offers the user the option of two different plots:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pp_check.foo &lt;-<span class="st"> </span>function(object, ..., <span class="dt">type =</span> <span class="kw">c</span>(<span class="st">"multiple"</span>, <span class="st">"overlaid"</span>)) {
  y &lt;-<span class="st"> </span>object[[<span class="st">"y"</span>]]
  yrep &lt;-<span class="st"> </span>object[[<span class="st">"yrep"</span>]]
  switch(
    <span class="kw">match.arg</span>(type),
    <span class="dt">multiple =</span> <span class="kw"><a href="../reference/PPC-distributions.html">ppc_hist</a></span>(y, yrep[<span class="dv">1</span>:<span class="kw">min</span>(<span class="dv">8</span>, <span class="kw">nrow</span>(yrep)),, <span class="dt">drop =</span> <span class="ot">FALSE</span>]),
    <span class="dt">overlaid =</span> <span class="kw"><a href="../reference/PPC-distributions.html">ppc_dens_overlay</a></span>(y, yrep)
  )
}</code></pre></div>
<p>To try out <code>pp_check.foo</code> we can just make a list with <code>y</code> and <code>yrep</code> components and give it class <code>foo</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">y =</span> <span class="kw">rnorm</span>(<span class="dv">50</span>), <span class="dt">yrep =</span> <span class="kw">matrix</span>(<span class="kw">rnorm</span>(<span class="dv">5000</span>), <span class="dt">nrow =</span> <span class="dv">100</span>, <span class="dt">ncol =</span> <span class="dv">50</span>))
<span class="kw">class</span>(x) &lt;-<span class="st"> "foo"</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/pp_check.html">pp_check</a></span>(x)</code></pre></div>
<p><img src="PPC_files/figure-html/print-1-1.png" width="60%" style="display: block; margin: auto;"></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/pp_check.html">pp_check</a></span>(x, <span class="dt">type =</span> <span class="st">"overlaid"</span>)</code></pre></div>
<p><img src="PPC_files/figure-html/pp_check-2-1.png" width="60%" style="display: block; margin: auto;"></p>
</div>
<div id="examples-of-pp_check-methods-in-other-packages" class="section level3">
<h3 class="hasAnchor">
<a href="#examples-of-pp_check-methods-in-other-packages" class="anchor"></a>Examples of <code>pp_check</code> methods in other packages</h3>
<p>Several packages currently (or will soon) use this approach to provide an interface to <strong>bayesplot</strong>’s graphical posterior predictive checks. See, for example, the <code>pp_check</code> methods in the <a href="https://github.com/stan-dev/rstanarm"><strong>rstanarm</strong></a> and <a href="https://github.com/paul-buerkner/brms"><strong>brms</strong></a> packages.</p>
</div>
</div>
<div id="references" class="section level2">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<p>Buerkner, P. (2018). brms: Bayesian Regression Models using Stan. R package version 1.4.0. <a href="https://CRAN.R-project.org/package=brms" class="uri">https://CRAN.R-project.org/package=brms</a></p>
<p>Gabry, J., and Goodrich, B. (2017). rstanarm: Bayesian Applied Regression Modeling via Stan. R package version 2.14.1. <a href="http://mc-stan.org/interfaces/rstanarm.html" class="uri">http://mc-stan.org/interfaces/rstanarm.html</a>, <a href="https://CRAN.R-project.org/package=rstanarm" class="uri">https://CRAN.R-project.org/package=rstanarm</a></p>
<p>Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., and Rubin, D. B. (2013). <em>Bayesian Data Analysis</em>. Chapman &amp; Hall/CRC Press, London, third edition.</p>
<p>Stan Development Team. (2016). <em>Stan Modeling Language Users Guide and Reference Manual</em>. <a href="http://mc-stan.org/documentation/" class="uri">http://mc-stan.org/documentation/</a></p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#overview">Overview</a></li>
      <li><a href="#graphical-posterior-predictive-checks">Graphical posterior predictive checks</a></li>
      <li><a href="#providing-an-interface-to-bayesplot-ppcs-from-another-package">Providing an interface to bayesplot PPCs from another package</a></li>
      <li><a href="#references">References</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Jonah Gabry.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
